{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c nfl-health-and-safety-helmet-assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!unzip -o nfl-health-and-safety-helmet-assignment.zip -d \"./data/\"\n",
    "!rm nfl-health-and-safety-helmet-assignment.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil as sh\n",
    "from itertools import accumulate\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import supervision as sv\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU availability\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(r\".\\data\")\n",
    "images_dir = BASE_DIR / \"images\"\n",
    "images_lables_csv = BASE_DIR / \"image_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Path(images_dir).glob(\"*.jpg\")\n",
    "images = list(images)\n",
    "img_labels = pd.read_csv(images_lables_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotated_img(\n",
    "    image_path: Path, annotation_df: pd.DataFrame\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    curr_image = Image.open(image_path)\n",
    "    img_name = image_path.name\n",
    "    curr_img_lbl = annotation_df.query(\"image == @img_name\")\n",
    "    curr_lbl_xywh = curr_img_lbl[[\"left\", \"top\", \"width\", \"height\"]].values\n",
    "    curr_lbl_xyxy = tv.ops.box_convert(\n",
    "        torch.Tensor(curr_lbl_xywh),\n",
    "        in_fmt=\"xywh\",\n",
    "        out_fmt=\"xyxy\",\n",
    "    ).numpy()\n",
    "    labels = sv.Detections(xyxy=curr_lbl_xyxy)\n",
    "    annotations = sv.BoxAnnotator(\n",
    "        color=sv.Color(0, 0, 255),\n",
    "    ).annotate(np.array(curr_image.copy()), labels, skip_label=True)\n",
    "    # annotated_img = Image.fromarray(annotations)\n",
    "    return np.array(curr_image.copy()), curr_lbl_xyxy, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_img_idx = np.random.randint(0, len(images))\n",
    "print(curr_img_idx)\n",
    "img = images[curr_img_idx]\n",
    "curr_image, curr_lbl_xyxy, annotated_img = get_annotated_img(img, img_labels)\n",
    "annotated_img = Image.fromarray(annotated_img)\n",
    "\n",
    "annotated_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels[\"label\"].value_counts()\n",
    "\n",
    "label_mapping = {\n",
    "    \"Helmet\": 0,\n",
    "    \"Helmet-Blurred\": 1,\n",
    "    \"Helmet-Sideline\": 2,\n",
    "    \"Helmet-Partial\": 3,\n",
    "    \"Helmet-Difficult\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = img_labels.copy()\n",
    "images = temp_df[\"image\"].unique()\n",
    "print(len(images))\n",
    "\n",
    "np.random.seed(47)\n",
    "\n",
    "pp(images[:5])\n",
    "np.random.shuffle(images)\n",
    "pp(images[:5])\n",
    "\n",
    "num_images = len(images)\n",
    "split_index = [0.7, 0.2, 0.1]\n",
    "train_idx, valid_idx, test_idx = [ceil(num_images * i) for i in split_index]\n",
    "train_idx, valid_idx, test_idx = list(accumulate([train_idx, valid_idx, test_idx]))\n",
    "\n",
    "train_images, valid_images, test_images = np.split(images, [train_idx, valid_idx])\n",
    "train_df, valid_df, test_df = (\n",
    "    temp_df.query(\"image in @train_images\"),\n",
    "    temp_df.query(\"image in @valid_images\"),\n",
    "    temp_df.query(\"image in @test_images\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape, test_df.shape, valid_df.shape)\n",
    "print(train_df[\"label\"].value_counts())\n",
    "print(test_df[\"label\"].value_counts())\n",
    "print(valid_df[\"label\"].value_counts())\n",
    "\n",
    "print(\n",
    "    len(train_df[\"image\"].unique()),\n",
    "    len(test_df[\"image\"].unique()),\n",
    "    len(valid_df[\"image\"].unique()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Images and annotations to different directories\n",
    "- Move images and annotations to directories\n",
    "- Convert dataset to YOLO8 required format (scaling annotations by image dimensions) \n",
    "- [Dataset Format Reference](https://docs.ultralytics.com/datasets/detect/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y8_dataset_ouput_path = Path(r\".\\y8_image_dataset_split\")  # fmt: skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = (\n",
    "    (y8_dataset_ouput_path / \"train\", train_df),\n",
    "    (y8_dataset_ouput_path / \"valid\", valid_df),\n",
    "    (y8_dataset_ouput_path / \"test\", test_df),\n",
    ")\n",
    "\n",
    "for out_dir, curr_df in directories:\n",
    "    out_img_dir = out_dir / \"images\"\n",
    "    out_img_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    out_lbl_dir = out_dir / \"labels\"\n",
    "    out_lbl_dir.mkdir(exist_ok=True, parents=True)\n",
    "    curr_df[\"class_id\"] = curr_df[\"label\"].map(label_mapping)\n",
    "    curr_df_grouped = curr_df.groupby([\"image\"])\n",
    "\n",
    "    for img_name in curr_df[\"image\"].unique():\n",
    "        # copy image\n",
    "        img_path = images_dir / img_name\n",
    "        out_img_path = out_img_dir / img_name\n",
    "        img_width, img_height = Image.open(img_path).size\n",
    "        sh.copyfile(img_path, out_img_path)\n",
    "\n",
    "        # convert label and write file\n",
    "        out_label_path = out_lbl_dir / f\"{img_path.stem}.txt\"\n",
    "        curr_group = curr_df_grouped.get_group(img_name)\n",
    "        bboxes_xywh = curr_group[[\"left\", \"top\", \"width\", \"height\"]].values\n",
    "        bboxes_cxcywh = tv.ops.box_convert(\n",
    "            boxes=torch.tensor(bboxes_xywh),\n",
    "            in_fmt=\"xywh\",\n",
    "            out_fmt=\"cxcywh\",\n",
    "        )\n",
    "        bboxes_cxcywh_np = bboxes_cxcywh.numpy().astype(float)\n",
    "        bboxes_cxcywh_np[:, 0] /= img_width  # x_center\n",
    "        bboxes_cxcywh_np[:, 2] /= img_width  # width\n",
    "        bboxes_cxcywh_np[:, 1] /= img_height  # y_center\n",
    "        bboxes_cxcywh_np[:, 3] /= img_height  # height\n",
    "        class_ids = curr_group[[\"class_id\"]].values\n",
    "        final_labels = np.hstack([class_ids, bboxes_cxcywh_np])\n",
    "        temp_lbl_df = pd.DataFrame(final_labels)\n",
    "        temp_lbl_df.to_csv(out_label_path, header=False, index=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Training Config YAML\n",
    "\n",
    "References\n",
    "- [YOLOv8 Train](https://docs.ultralytics.com/tasks/detect/#train)\n",
    "- [Training Config](https://docs.ultralytics.com/usage/cfg/#train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minor hack to use python variables with %%writefile\n",
    "# - https://github.com/ipython/ipython/issues/6701\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, \"w\") as f:\n",
    "        f.write(cell.format(**globals()))\n",
    "\n",
    "\n",
    "pwd = str(Path(\".\").absolute())\n",
    "pwd = list(pwd)\n",
    "pwd[0] = pwd[0].upper()\n",
    "pwd = \"\".join(pwd)\n",
    "# print(pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate y8_train_config.yaml\n",
    "\n",
    "train: {pwd}\\y8_image_dataset_split\\train\n",
    "val: {pwd}\\y8_image_dataset_split\\valid\n",
    "test: {pwd}\\y8_image_dataset_split\\test\n",
    "\n",
    "nc: 5\n",
    "\n",
    "names:\n",
    "  0: 'Helmet'\n",
    "  1: 'Helmet-Blurred'\n",
    "  2: 'Helmet-Sideline'\n",
    "  3: 'Helmet-Partial'\n",
    "  4: 'Helmet-Difficult'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg_path = \"./y8_train_config.yaml\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "results = model.train(data=train_cfg_path, epochs=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\".\\data\\images\\57502_000480_Endzone_frame0495.jpg\"\n",
    "\n",
    "loaded_model = YOLO(\"./yolo8_model.pt\")\n",
    "results = loaded_model(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "box_annotator = sv.BoxAnnotator(thickness=2, text_thickness=1, text_scale=0.5)\n",
    "\n",
    "\n",
    "r = results[0]\n",
    "detections = sv.Detections.from_ultralytics(r)\n",
    "img = r.orig_img\n",
    "\n",
    "frame = box_annotator.annotate(scene=img, detections=detections)\n",
    "Image.fromarray(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
